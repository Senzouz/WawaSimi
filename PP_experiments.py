# -*- coding: utf-8 -*-
"""AlexPP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KvO1DytxBAlzHao9N2uDHzE_bfMYEj_t

#Phonological Processes Identification

##Dataset Loading
"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

fid = drive.ListFile({'q':"title='VC Mal Pronunciadas.zip'"}).GetList()[0]['id']
m = drive.CreateFile({'id': fid})
m.GetContentFile('data.zip')

!unzip data.zip -d ''

"""##Data Preprocessing"""

import os
import librosa
import skimage.io
from skimage.transform import resize
from skimage import img_as_ubyte
from skimage.color import gray2rgb
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

def scale_minmax(X, min=0.0, max=1.0):
    X_std = (X - X.min()) / (X.max() - X.min())
    X_scaled = X_std * (max - min) + min
    return X_scaled

def spectrogram_image(y, sr):
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    img = scale_minmax(mfcc, 0, 255).astype(np.uint8)
    img = np.flip(img, axis=0)
    img = 255-img

    return img

"""##Known Speaker Approach"""

specgrams = []
archivos = os.listdir('VC Mal Pronunciadas')
archivos.sort()
for audio in archivos:
  array = audio.split('_')
  temp = audio[:8]
  if audio.endswith('.wav') and array[2] != 'RR':
    y, sr = librosa.load('VC Mal Pronunciadas/' + audio)
    image = spectrogram_image(y, sr)
    image_resized = resize(image, (224, 224), anti_aliasing=True)
    if audio.endswith('bubanda.wav') or audio.endswith('platamo.wav') or audio.endswith('madiposa.wav') or audio.endswith('gufanda.wav') or audio.endswith('lilicoptero.wav'):
        specgrams.append([image_resized, 1])
    elif audio.endswith('ficio.wav') or audio.endswith('fisio.wav') or audio.endswith('buante.wav') or audio.endswith('poca.wav') or audio.endswith('marifosa.wav') or audio.endswith('tien.wav'):
        specgrams.append([image_resized, 2])
    else:
        specgrams.append([image_resized, 0])

df_KS = pd.DataFrame(specgrams)
df_KS = df_KS.sample(frac=1).reset_index(drop=True)

from sklearn.model_selection import train_test_split
x_train, x_test = train_test_split(df_KS, test_size=0.3)

"""###Import and Modify Alexnet"""

import torch
import torch.nn as nn
import torch.utils.data as data_utils
import torch.optim as optim

torch.hub._validate_not_a_forked_repo=lambda a,b,c: True
AlexNet_model_KS = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)

AlexNet_model_KS.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
AlexNet_model_KS.classifier[4] = nn.Linear(4096,1024)
AlexNet_model_KS.classifier[6] = nn.Linear(1024,3)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
AlexNet_model_KS.to(device)

"""###Train"""

def toDataLoader(data):
  input = torch.tensor(list(data[0].to_numpy()))
  target = torch.tensor(list(data[1])).type(torch.LongTensor)
  tensor = data_utils.TensorDataset(input, target) 
  loader = data_utils.DataLoader(dataset = tensor, batch_size=4, shuffle=True, num_workers=2)
  return loader

#Loss
criterion = nn.CrossEntropyLoss()

#Optimizer(SGD)
optimizer = optim.Adam(AlexNet_model_KS.parameters(), lr=0.00001)

train_loader = toDataLoader(x_train)

for epoch in range(30):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        
        optimizer.zero_grad()

        inputs = inputs.unsqueeze(1)

        # forward + backward + optimize
        output = AlexNet_model_KS(inputs.float())
        loss = criterion(output,labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 150 == 149:
            print('[%d, %5d] loss: %d - %.3f' %
                  (epoch + 1, i + 1, running_loss, running_loss / 150))
            running_loss = 0.0

print('Finished Training of AlexNet')

"""###Test"""

def calculateConfusionMatrix(predicted, true):
  for i in range (3):
    if predicted == true and predicted == i:
      TP[i] += 1
    elif predicted == true:
      TN[i] += 1
    elif predicted != true and predicted == i:
      FP[i] += 1
    elif predicted != true:
      FN[i] += 1

test_loader = toDataLoader(x_test)

#Testing Accuracy
correct = 0
total = 0
TP = [0 for fila in range (0,3)]
TN = [0 for fila in range (0,3)]
FN = [0 for fila in range (0,3)]
FP = [0 for fila in range (0,3)]

with torch.no_grad():
  for data in test_loader:
    images, labels = data[0].to(device), data[1].to(device)
    images = images.unsqueeze(1)
    outputs = AlexNet_model_KS(images.float())
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

    for j in range(len(predicted)):
      calculateConfusionMatrix(predicted[j], labels[j])

print('Accuracy test: %d%%' % (100 * correct / total))

for i in range(len(TP)):
  print('Class %d' % i)
  print('%d\t%d' % (TP[i], FN[i]))
  print('%d\t%d' % (FP[i], TN[i]))
  print('Accuracy: %d%%' % (100 * (TP[i] + TN[i]) / (TP[i] + TN[i] + FN[i] + FP[i])))
  print('Precision: %d%%' % (100 * TP[i] / (TP[i] + FP[i])))
  print('Recall: %d%%' % (100 * TP[i] / (TP[i] + FN[i])))
  print('------------------------------')
  print('------------------------------')

"""##Uknown Speaker Approach"""

acurracies = []
precisions = []
recalls = []

pitch = ['253', '255', '309']
sr = ['5', '7']
names = ['BM', 'CA', 'DJ', 'DM', 'EC', 'EV', 'IL', 'JE', 'KM', 'LZ', 'MB', 'OF', 'VL', 'WH']

lista = []
for i in pitch:
  for j in sr:
    for name in names:
      lista.append(i + '_' + j + '_' + name)

import random
while len(lista_test) < 25:
  num = random.randint(0, 83)
  if lista[num] not in lista_test:
    lista_test.append(lista[num])

specgrams1 = []
specgrams2 = []

archivos = os.listdir('VC Mal Pronunciadas')
for audio in archivos:
  array = audio.split('_')
  temp = audio[:8]
  if audio.endswith('.wav') and array[2] != 'RR':
    y, sr = librosa.load('VC Mal Pronunciadas/' + audio)
    image = spectrogram_image(y, sr)
    image_resized = resize(image, (224, 224), anti_aliasing=True)
    if temp in lista_test:
      if audio.endswith('bubanda.wav') or audio.endswith('platamo.wav') or audio.endswith('madiposa.wav') or audio.endswith('gufanda.wav') or audio.endswith('lilicoptero.wav'):
        specgrams2.append([image_resized, 1])
      elif audio.endswith('ficio.wav') or audio.endswith('fisio.wav') or audio.endswith('buante.wav') or audio.endswith('poca.wav') or audio.endswith('marifosa.wav') or audio.endswith('tien.wav'):
        specgrams2.append([image_resized, 2])
      else:
        specgrams2.append([image_resized, 0])
    else:
      if audio.endswith('bubanda.wav') or audio.endswith('platamo.wav') or audio.endswith('madiposa.wav') or audio.endswith('gufanda.wav') or audio.endswith('lilicoptero.wav'):
        specgrams1.append([image_resized, 1])
      elif audio.endswith('ficio.wav') or audio.endswith('fisio.wav') or audio.endswith('buante.wav') or audio.endswith('poca.wav') or audio.endswith('marifosa.wav') or audio.endswith('tien.wav'):
        specgrams1.append([image_resized, 2])
      else:
        specgrams1.append([image_resized, 0])

df_US_train = pd.DataFrame(specgrams1)
df_US_train = df_US_train.sample(frac=1).reset_index(drop=True)
df_US_test = pd.DataFrame(specgrams2)
df_US_test = df_US_test.sample(frac=1).reset_index(drop=True)

"""###Import and Modify Alexnet"""

import torch
import torch.nn as nn
import torch.utils.data as data_utils
import torch.optim as optim

torch.hub._validate_not_a_forked_repo=lambda a,b,c: True
AlexNet_model_US = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)

AlexNet_model_US.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
AlexNet_model_US.classifier[4] = nn.Linear(4096,1024)
AlexNet_model_US.classifier[6] = nn.Linear(1024,3)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
AlexNet_model_US.to(device)

"""###Train"""

def toDataLoader(data):
  input = torch.tensor(list(data[0].to_numpy()))
  target = torch.tensor(list(data[1])).type(torch.LongTensor)
  tensor = data_utils.TensorDataset(input, target) 
  loader = data_utils.DataLoader(dataset = tensor, batch_size=4, shuffle=True, num_workers=2)
  return loader

#Loss
criterion = nn.CrossEntropyLoss()

#Optimizer(SGD)
optimizer = optim.Adam(AlexNet_model_US.parameters(), lr=0.00001)

train_loader = toDataLoader(df_US_train)

for epoch in range(20):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # obtener los inputs; "data" es una lista de [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)
        
        optimizer.zero_grad()

        inputs = inputs.unsqueeze(1)

        # forward + backward + optimize
        output = AlexNet_model_US(inputs.float())
        loss = criterion(output,labels)
        loss.backward()
        optimizer.step()

        # imprimir estadÃ­sticas
        running_loss += loss.item()
        if i % 150 == 149:
            print('[%d, %5d] loss: %d - %.3f' %
                  (epoch + 1, i + 1, running_loss, running_loss / 150))
            running_loss = 0.0

print('Finished Training of AlexNet')

"""###Test"""

def calculateConfusionMatrix(predicted, true):
  for i in range (3):
    if predicted == true and predicted == i:
      TP[i] += 1
    elif predicted == true:
      TN[i] += 1
    elif predicted != true and predicted == i:
      FP[i] += 1
    elif predicted != true:
      FN[i] += 1

test_loader = toDataLoader(df_US_test)

#Testing Accuracy
correct = 0
total = 0
TP = [0 for fila in range (0,3)]
TN = [0 for fila in range (0,3)]
FN = [0 for fila in range (0,3)]
FP = [0 for fila in range (0,3)]

with torch.no_grad():
  for data in test_loader:
    images, labels = data[0].to(device), data[1].to(device)
    images = images.unsqueeze(1)
    outputs = AlexNet_model_US(images.float())
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

    for j in range(len(predicted)):
      calculateConfusionMatrix(predicted[j], labels[j])

print('Accuracy test: %d%%' % (100 * correct / total))

for i in range(len(TP)):
  print('Class %d' % i)
  print('%d\t%d' % (TP[i], FN[i]))
  print('%d\t%d' % (FP[i], TN[i]))
  print('Accuracy: %d%%' % (100 * (TP[i] + TN[i]) / (TP[i] + TN[i] + FN[i] + FP[i])))
  print('Precision: %d%%' % (100 * TP[i] / (TP[i] + FP[i])))
  print('Recall: %d%%' % (100 * TP[i] / (TP[i] + FN[i])))
  print('------------------------------')
  print('------------------------------')

torch.save(AlexNet_model_US, 'AlexNet_PP_30.pkl')