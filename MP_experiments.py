# -*- coding: utf-8 -*-
"""Transfer Learning 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dz4URT_Zd--S39_wf_xsGB2Dj3Vk_ker

#Mispronunciation Detection

##Dataset Loading
"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

fid = drive.ListFile({'q':"title='VC Mal Pronunciadas.zip'"}).GetList()[0]['id']
m = drive.CreateFile({'id': fid})
m.GetContentFile('data.zip')

!unzip data.zip -d ''

fid = drive.ListFile({'q':"title='VC Bien Pronunciadas.zip'"}).GetList()[0]['id']
m = drive.CreateFile({'id': fid})
m.GetContentFile('data2.zip')

!unzip data2.zip -d ''

"""##Data Preprocessing"""

import os
import librosa
import skimage.io
from skimage.transform import resize
from skimage import img_as_ubyte
from skimage.color import gray2rgb
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

def scale_minmax(X, min=0.0, max=1.0):
    X_std = (X - X.min()) / (X.max() - X.min())
    X_scaled = X_std * (max - min) + min
    return X_scaled

def spectrogram_image(y, sr):
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    img = scale_minmax(mfcc, 0, 255).astype(np.uint8)
    img = np.flip(img, axis=0)
    img = 255-img

    return img

"""##Known Speaker Approach"""

specgrams = []
archivos = os.listdir('VC Mal Pronunciadas')
for audio in archivos:
  array = audio.split('_')
  temp = audio[:8]
  if audio.endswith('.wav') and array[2] != 'RR':
    y, sr = librosa.load('VC Mal Pronunciadas/' + audio)
    image = spectrogram_image(y, sr)
    image_resized = resize(image, (224, 224), anti_aliasing=True)
    specgrams.append([image_resized, 0])

archivos = os.listdir('VC Bien Pronunciadas')
for audio in archivos:
  array = audio.split('_')
  temp = audio[:8]
  if audio.endswith('.wav') and array[2] != 'RR':
    y, sr = librosa.load('VC Bien Pronunciadas/' + audio)
    image = spectrogram_image(y, sr)
    image_resized = resize(image, (224, 224), anti_aliasing=True)
    specgrams.append([image_resized, 1])

df_KS = pd.DataFrame(specgrams)
df_KS = df_KS.sample(frac=1).reset_index(drop=True)

from sklearn.model_selection import train_test_split
x_train, x_test = train_test_split(df_KS, test_size=0.3)

"""###Import and Modify Alexnet"""

import torch
import torch.nn as nn
import torch.utils.data as data_utils
import torch.optim as optim

torch.hub._validate_not_a_forked_repo=lambda a,b,c: True
AlexNet_model_KS = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)

AlexNet_model_KS.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
AlexNet_model_KS.classifier[4] = nn.Linear(4096,1024)
AlexNet_model_KS.classifier[6] = nn.Linear(1024,2)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
AlexNet_model_KS.to(device)

"""###Train"""

def toDataLoader(data):
  input = torch.tensor(list(data[0].to_numpy()))
  target = torch.tensor(list(data[1])).type(torch.LongTensor)
  tensor = data_utils.TensorDataset(input, target) 
  loader = data_utils.DataLoader(dataset = tensor, batch_size=4, shuffle=True)
  return loader

#Loss
criterion = nn.CrossEntropyLoss()

#Optimizer(Adam)
optimizer = optim.Adam(AlexNet_model_KS.parameters(), lr=0.00001)

train_loader = toDataLoader(x_train)

for epoch in range(30):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        inputs, labels = data[0].to(device), data[1].to(device)
        
        optimizer.zero_grad()

        inputs = inputs.unsqueeze(1)

        # forward + backward + optimize
        output = AlexNet_model_KS(inputs.float())
        loss = criterion(output,labels)
        loss.backward()
        optimizer.step()

        # imprimir estadísticas
        running_loss += loss.item()
        if i % 150 == 149:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 150))
            running_loss = 0.0

print('Finished Training of AlexNet')

"""###Test"""

test_loader = toDataLoader(x_test)

#Testing Accuracy
correct = 0
total = 0
TP = 0
TN = 0
FN = 0
FP = 0

with torch.no_grad():
    for data in test_loader:
        images, labels = data[0].to(device), data[1].to(device)
        images = images.unsqueeze(1)
        outputs = AlexNet_model(images.float())
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)

        for j in range(len(predicted)):
            if predicted[j] == labels[j] and predicted[j] == 0:
                TP += 1
            if predicted[j] == labels[j] and predicted[j] == 1:
                TN += 1
            if predicted[j] != labels[j] and predicted[j] == 0:
                FP += 1
            if predicted[j] != labels[j] and predicted[j] == 1:
                FN += 1
        
        correct += (predicted == labels).sum().item()

print('%d\t%d' % (TP, FN))
print('%d\t%d' % (FP, TN))
print('Accuracy test: %d%%' % (100 *(TP + TN) / (TP + TN + FN + FP)))
print('Precision test: %d%%' % (100 * TP / (TP + FP)))
print('Recall test: %d%%' % (100 * TP / (TP + FN)))

"""##Uknown Speaker Approach"""

acurracies = []
precisions = []
recalls = []

pitch = ['253', '255', '309']
sr = ['5', '7']
names = ['BM', 'CA', 'DJ', 'DM', 'EC', 'EV', 'IL', 'JE', 'KM', 'LZ', 'MB', 'OF', 'VL', 'WH']

lista = []
for i in pitch:
  for j in sr:
    for name in names:
      lista.append(i + '_' + j + '_' + name)

lista_test = []

import random
while len(lista_test) < 25:
  num = random.randint(0, 83)
  if lista[num] not in lista_test:
    lista_test.append(lista[num])

specgrams1 = []
specgrams2 = []
archivos = os.listdir('VC Mal Pronunciadas')
for audio in archivos:
  array = audio.split('_')
  temp = audio[:8]
  if audio.endswith('.wav') and array[2] != 'RR':
    y, sr = librosa.load('VC Mal Pronunciadas/' + audio)
    image = spectrogram_image(y, sr)
    image_resized = resize(image, (224, 224), anti_aliasing=True)
    if temp in lista_test:
      specgrams2.append([image_resized, 0])
    else:
      specgrams1.append([image_resized, 0])

archivos = os.listdir('VC Bien Pronunciadas')
for audio in archivos:
  array = audio.split('_')
  temp = audio[:8]
  if audio.endswith('.wav') and array[2] != 'RR':
    y, sr = librosa.load('VC Bien Pronunciadas/' + audio)
    image = spectrogram_image(y, sr)
    image_resized = resize(image, (224, 224), anti_aliasing=True)
    if temp in lista_test:
      specgrams2.append([image_resized, 1])
    else:
      specgrams1.append([image_resized, 1])

df_UK_train = pd.DataFrame(specgrams1)
df_UK_train = df_UK_train.sample(frac=1).reset_index(drop=True)
df_UK_test = pd.DataFrame(specgrams2)
df_UK_test = df_UK_test.sample(frac=1).reset_index(drop=True)

"""###Import and Modify Alexnet"""

import torch
import torch.nn as nn
import torch.utils.data as data_utils
import torch.optim as optim

torch.hub._validate_not_a_forked_repo=lambda a,b,c: True
AlexNet_model_US = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)

AlexNet_model_US.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
AlexNet_model_US.classifier[4] = nn.Linear(4096,1024)
AlexNet_model_US.classifier[6] = nn.Linear(1024,2)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
AlexNet_model_US.to(device)

"""###Train"""

def toDataLoader(data):
  input = torch.tensor(list(data[0].to_numpy()))
  target = torch.tensor(list(data[1])).type(torch.LongTensor)
  tensor = data_utils.TensorDataset(input, target) 
  loader = data_utils.DataLoader(dataset = tensor, batch_size=4, shuffle=True)
  return loader

#Loss
criterion = nn.CrossEntropyLoss()

#Optimizer(Adam)
optimizer = optim.Adam(AlexNet_model_US.parameters(), lr=0.00001)

train_loader = toDataLoader(df_UK_train)

for epoch in range(30):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # obtener los inputs; "data" es una lista de [inputs, labels]
        inputs, labels = data[0].to(device), data[1].to(device)
        
        optimizer.zero_grad()

        inputs = inputs.unsqueeze(1)

        # forward + backward + optimize
        output = AlexNet_model_US(inputs.float())
        loss = criterion(output,labels)
        loss.backward()
        optimizer.step()

        # imprimir estadísticas
        running_loss += loss.item()
        if i % 150 == 149:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 150))
            running_loss = 0.0

print('Finished Training of AlexNet')

"""###Test"""

test_loader = toDataLoader(df_UK_test)

#Testing Accuracy
correct = 0
total = 0
TP = 0
TN = 0
FN = 0
FP = 0

with torch.no_grad():
    for data in test_loader:
        images, labels = data[0].to(device), data[1].to(device)
        images = images.unsqueeze(1)
        outputs = AlexNet_model_US(images.float())
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)

        for j in range(len(predicted)):
            if predicted[j] == labels[j] and predicted[j] == 0:
                TP += 1
            if predicted[j] == labels[j] and predicted[j] == 1:
                TN += 1
            if predicted[j] != labels[j] and predicted[j] == 0:
                FP += 1
            if predicted[j] != labels[j] and predicted[j] == 1:
                FN += 1
        
        correct += (predicted == labels).sum().item()

print('%d\t%d' % (TP, FN))
print('%d\t%d' % (FP, TN))
print('Accuracy test: %d%%' % (100 *(TP + TN) / (TP + TN + FN + FP)))
print('Precision test: %d%%' % (100 * TP / (TP + FP)))
print('Recall test: %d%%' % (100 * TP / (TP + FN)))

torch.save(AlexNet_model_US, 'AlexNet_MP_30.pkl')